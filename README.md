This project focuses on analyzing a dataset of BBC News articles categorized into five topics. The dataset includes key information such as the articleâ€™s category, filename, title, and full content. By leveraging various machine learning techniques, the project aims to preprocess text data, extract meaningful features, and apply unsupervised learning methods to discover hidden structures and topics in the articles.

Through this project, I implemented several essential steps in text analysis and clustering, including:

* **Text Preprocessing**: Cleaning and preparing textual data by removing stopwords, punctuation, and performing lemmatization. This ensures that the text is structured optimally for further analysis.

* **Feature Extraction using TF-IDF**: Converting the textual data into numerical representations using Term Frequency-Inverse Document Frequency (TF-IDF) to highlight important words in each article.

* **Dimensionality Reduction with PCA & t-SNE**: Reducing the high-dimensional feature space using Principal Component Analysis (PCA) and t-SNE to better visualize and structure the data for clustering.

* **Unsupervised Clustering with K-Means**: Applying the K-Means algorithm to group similar articles together based on their content.

* **Topic Modeling with Latent Dirichlet Allocation (LDA)**: Extracting meaningful topics from the dataset by analyzing word distributions and identifying key themes in each cluster.

* **Visualization and Evaluation**: Using various visualization techniques such as word clouds, t-SNE plots, and cluster heatmaps to interpret and analyze the results effectively.

This project serves as a comprehensive exploration of text-based clustering and topic modeling, demonstrating how machine learning can be used to organize and extract insights from unstructured textual data. The results help in understanding patterns within news articles and provide a foundation for applications such as document classification and automated content organization.

